<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html lang='en'>
<head>
<title>2.13.0.md</title>
<meta content='text/html; charset=UTF-8' http-equiv='Content-Type'>
<link href='../../../css/style.css' media='screen' rel='stylesheet' type='text/css'>
<script type='text/javascript'>
  function popupCode(url) {
    window.open(url, "Code", "resizable=yes,scrollbars=yes,toolbar=no,status=no,height=150,width=400")
  }
  
  function toggleCode(id) {
    var code = document.getElementById(id)
  
    code.style.display = code.style.display != 'block' ? 'block' : 'none'
    return true
  }
  
  // Make codeblocks hidden by default
  document.writeln('<' + 'style type="text/css">.method .source pre { display: none }<\/style>')
</script>
</head>
<body class='page'>
<div class='file' id='wrapper'>
<div class='header'>
<h1 class='name'>2.13.0.md
</h1>
<div class='paths'>
doc/release_notes/2.13.0.md
</div>
<div class='last-update'>
Last Update:
<span class='datetime'>2018-11-04 20:33:33 +0100</span>
</div>
</div>
<div id='content'>
<div id='text'>
<div id='description'>
<h2 id="label-New+features">New features<span><a href="#label-New+features">&para;</a> <a href="#top">&uarr;</a></span></h2>
<ul><li>
<p>The S3 object URLs can now be signed with a custom signer. This enables 
serving private objects via AWS CloudFront by signing the URLs with the 
signer from the <code>aws-sdk-cloudfront</code> gem.</p>
</li></ul>

<p>“`rb  require “aws-sdk-cloudfront”</p>

<p>signer = Aws::CloudFront::UrlSigner.new(  key_pair_id: “cf-keypair-id”, 
private_key_path: “./cf_private_key.pem”,  )</p>

<p><a
href="../../../classes/Shrine/Storage/S3.html#method-c-new">Shrine::Storage::S3.new</a>(signer:
signer.method(:signed_url))  “`</p>
<ul><li>
<p>To make your S3 storage public, previously you needed to do two things: set
the <code>acl: &quot;public-read&quot;</code> upload option and set pass
<code>public: true</code> when  generating a URL.</p>
</li></ul>

<p>“`rb  Shrine.storages = {  cache: <a
href="../../../classes/Shrine/Storage/S3.html#method-c-new">Shrine::Storage::S3.new</a>(upload_options:
{ acl: “public-read” }, <strong>options),  store: <a
href="../../../classes/Shrine/Storage/S3.html#method-c-new">Shrine::Storage::S3.new</a>(upload_options:
{ acl: “public-read” }, </strong>options),  }</p>

<p>Shrine.plugin :default_url_options,  cache: { public: true },  store: {
public: true }  “`</p>

<p>Now you can achieve the same thing just by setting <code>public:&#x000A;true</code> when  initializing the S3 storage.</p>

<p><code>rb   Shrine.storages = {     cache: Shrine::Storage::S3.new(public:&#x000A;true, **options),     store: Shrine::Storage::S3.new(public: true,&#x000A;**options),   } </code></p>
<ul><li>
<p>The <code>:force</code> option has been added to the
<code>infer_extension</code> plugin, which  makes the extension always
determined from the MIME type, regardless of  whether it exists or not.</p>
</li></ul>

<p><code>rb   Shrine.plugin :infer_extension, force: true </code></p>

<p>This is useful for when you want to normalize the file extensions of
uploaded  files.</p>

<p><code>rb   uploader.upload(File.open(&quot;image.jpg&quot;))  #  &#x000A;uploader.upload(File.open(&quot;image.jpeg&quot;)) # all these will be&#x000A;uploaded with a .jpeg extension  &#x000A;uploader.upload(File.open(&quot;image.JPG&quot;))  # </code></p>
<ul><li>
<p><code>Shrine#upload</code> now accepts a <code>:metadata</code> option for
manually overrding the  extracted metadata.</p>
</li></ul>

<p><code>rb   uploaded_file = uploader.upload(file, metadata: {&#x000A;&quot;filename&quot; =&gt; &quot;my-file.txt&quot; })  &#x000A;uploaded_file.original_filename    #=&gt; &quot;my-file.txt&quot; </code></p>

<p>Furthermore, <code>Shrine::Attacher#assign</code> now forwards any
additional options to  <code>Shrine#upload</code>, so you can also override
metadata when attaching files.</p>

<p><code>rb   photo.image_attacher.assign(file, metadata: {&#x000A;&quot;mime_type&quot; =&gt; &quot;text/plain&quot; }) </code></p>

<h2 id="label-Other+improvements">Other improvements<span><a href="#label-Other+improvements">&para;</a> <a href="#top">&uarr;</a></span></h2>
<ul><li>
<p>It&#39;s now possible to use an S3 endpoint which requires bucket name to
be in  the URI path (e.g. Minio) with CDNs where bucket name shouldn&#39;t
be in the URI  path (e.g. CloudFront). Since version 2.11.0, when
initializing  <code>Shrine::Storage::S3</code> with <code>:endpoint</code>
with <code>:force_path_style</code>, generating  an URL with a
<code>:host</code> returned an URI with bucket name in the path. This 
introduced a regression for anyone relying on previous behaviour, so that 
change has been reverted, and this is the current behaviour:</p>
</li></ul>

<p>“`rb  s3 = <a
href="../../../classes/Shrine/Storage/S3.html#method-c-new">Shrine::Storage::S3.new</a>(endpoint:
“<a href="https://minio.example.com">minio.example.com</a>”)  s3.url(“foo”)
#=&gt; “<a
href="https://my-s3-endpoint.com/foo">my-s3-endpoint.com/foo</a>” 
s3.url(“foo”, host: “<a
href="https://123.cloudfront.net">123.cloudfront.net</a>”) #=&gt; “<a
href="https://123.cloudfront.net/foo">123.cloudfront.net/foo</a>”</p>

<p>s3 = <a
href="../../../classes/Shrine/Storage/S3.html#method-c-new">Shrine::Storage::S3.new</a>(endpoint:
“<a href="https://my-s3-endpoint.com">my-s3-endpoint.com</a>”,
force_path_style: true, **options)  s3.url(“foo”) #=&gt; “<a
href="https://my-s3-endpoint.com/my-bucket/foo">my-s3-endpoint.com/my-bucket/foo</a>”
s3.url(“foo”, host: “<a
href="https://123.cloudfront.net">123.cloudfront.net</a>”) #=&gt; “<a
href="https://123.cloudfront.net/foo">123.cloudfront.net/foo</a>”  “`</p>
<ul><li>
<p>The <code>:host</code> option to <code>Shrine::Storage::S3#url</code> now
handles URLs with  path prefixes, provided that the URL ends with a slash.</p>
</li></ul>

<p><code>rb   # old behaviour   s3.url(&quot;foo&quot;, host:&#x000A;&quot;https://example.com/prefix/&quot;) #=&gt;&#x000A;&quot;https://example.com/foo&quot;   # new behaviour  &#x000A;s3.url(&quot;foo&quot;, host: &quot;https://example.com/prefix/&quot;)&#x000A;#=&gt; &quot;https://example.com/prefix/foo&quot; </code></p>
<ul><li>
<p>Fixed error that would happen when uploading a file with a filename that
had  certain combination of UTF-8 characters to
<code>upload_endpoint</code>.</p>
</li><li>
<p>The <code>Content-Type</code> header in <code>upload_endpoint</code> and
<code>presign_endpoint</code>  responses now specifies
<code>charset=utf-8</code>.</p>
</li><li>
<p><code>Shrine::Storage::S3</code> now uses
<code>Aws::S3::Object#upload_stream</code> if available  when uploading
large IO streams which are not file objects, which uses  parallelized
multipart upload. This can make such uploads finish up to 2x  faster.</p>
</li><li>
<p><code>Shrine::Storage::S3</code> now uses
<code>Aws::S3::Object#upload_stream</code> if available  when uploading
files of unknown size.</p>
</li><li>
<p>The <code>upload_endpoint</code> now returns <code>Upload Not Valid</code>
error message when file  parameter was present but not in correct format
(previously <code>Upload Not   Found</code> was returned, which was a bit
misleading).</p>
</li></ul>

<h2 id="label-Backwards+compatibility">Backwards compatibility<span><a href="#label-Backwards+compatibility">&para;</a> <a href="#top">&uarr;</a></span></h2>
<ul><li>
<p>When <code>Shrine::Storage::S3</code> is initialized with
<code>:endpoint</code> with  <code>:force_path_style</code>, a file URL
generated with a <code>:host</code> will not include the  bucket name in
the URL path anymore. Users relying on this behaviour should  update their
code to include the bucket name in the <code>:host</code> URL path.</p>
</li></ul>

<p><code>rb   s3.url(&quot;foo&quot;, host:&#x000A;&quot;https://example.com/my-bucket/&quot;) </code></p>
<ul><li>
<p>Using aws-sdk-s3 older than 1.14 with <code>Shrine::Storage::S3</code> when
uploading  files with unknown size is now deprecated and won&#39;t be
supported in <a href="../../../classes/Shrine.html">Shrine</a> 3.</p>
</li></ul>

<p>Also, in this case <code>Shrine::Storage::S3</code> will now first copy the
whole file  onto disk before uploading it (previously only a chunk of the
input file was  copied to disk at a time).</p>

<p>If you&#39;re uploading files of unknown size (ones where
<code>#size</code> is not defined  or returns <code>nil</code>), you should
upgrade to aws-sdk-s3 1.14 or higher.</p>
</div>
<div id='context'>
</div>

</div>
</div>

<div id='footer-push'></div>
</div>
<div id='footer'>
<a href="https://github.com/rdoc/hanna-nouveau"><strong>Hanna Nouveau</strong> RDoc template</a>
</div>
</body>
</html>
